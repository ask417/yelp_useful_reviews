{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.21.0\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "# SK-learn for feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "#Encoding categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import sys\n",
    "print sys.version_info[0]\n",
    "print pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mutually_exclusive_elements(set1, set2):\n",
    "    set1ExclusiveElements = set(set1).symmetric_difference(set2).intersection(set1)\n",
    "    set2ExclusiveElements = set(set1).symmetric_difference(set2).intersection(set2)\n",
    "    print \"first: \", len(set1ExclusiveElements)\n",
    "    print \"second: \", len(set2ExclusiveElements)\n",
    "    return {\"first\": set1ExclusiveElements, \"second\": set2ExclusiveElements}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsnes = pd.read_json(open(\"data/yelp_training_set_business.json\"), lines=True)\n",
    "checkin = pd.read_json(open(\"data/yelp_training_set_checkin.json\"), lines=True)\n",
    "user = pd.read_json(open(\"data/yelp_training_set_user.json\"), lines=True)\n",
    "review = pd.read_json(open(\"data/yelp_training_set_review.json\"), lines=True)\n",
    "\n",
    "user = pd.concat([user.drop([\"votes\"], axis=1), user[\"votes\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "#Convert all checkin times to their own columns \n",
    "checkin = pd.concat([checkin.drop([\"checkin_info\"], axis=1), checkin[\"checkin_info\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "#Need to merge user level vote data to the test data by joining on user_id and imputing the rest. \n",
    "bsnes.rename(columns={'name': 'business_name', \n",
    "                      'review_count': 'business_review_count',\n",
    "                      'stars': 'business_stars'}, inplace=True)\n",
    "\n",
    "user.rename(columns={'name': 'user_name', \n",
    "                      'review_count': 'user_review_count',\n",
    "                      \"funny\": \"funny_votes_business\", \n",
    "                      \"useful\": \"useful_votes_business\",\n",
    "                      \"cool\": \"cool_votes_business\"}, inplace=True)\n",
    "\n",
    "review.rename(columns={'votes': 'useful_votes'}, inplace=True)\n",
    "\n",
    "totalRev = pd.merge(review, user, how='left', on=['user_id'])\n",
    "totalRev = pd.merge(totalRev, bsnes, how='left', on=['business_id'])\n",
    "totalRev = pd.merge(totalRev, checkin, how='left', on=['business_id'])\n",
    "totalRev.useful_votes = [i['useful'] for i in review.useful_votes]\n",
    "del totalRev[\"type_x\"]\n",
    "del totalRev[\"type_y\"]\n",
    "del totalRev[\"neighborhoods\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_variables = list(set(totalRev.select_dtypes(include=[\"object\",\"bool\"]).columns) - set([\"text\"]))\n",
    "numeric_variables = list(set(totalRev.columns) - set(categorical_variables) - set([\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "#  Encode Categorical Data\n",
    "#\n",
    "from collections import defaultdict\n",
    "leD = defaultdict(LabelEncoder)\n",
    "oheD = defaultdict(OneHotEncoder)\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "#Brilliiant, this both fits, transforms, and retains the fit in the dictionary \n",
    "categoricalTrainDataLE = totalRev[categorical_variables].apply(lambda x: leD[x.name].fit_transform(x))\n",
    "ohe = ohe.fit(categoricalTrainDataLE)\n",
    "categoricalTrainDataOHE = ohe.transform(categoricalTrainDataLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date  user_id  user_name\n",
      "0     4        4          2\n",
      "1     5        0          6\n",
      "2     7        1          5\n",
      "3     2        7          9\n",
      "4     6        8          7\n",
      "5     0        6          0\n",
      "6     1        9          4\n",
      "7     8        2          1\n",
      "8     9        3          8\n",
      "9     3        5          3\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print leTesting\n",
    "print oheTesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=3, max_features=None,\n",
    "                      strip_accents='unicode', analyzer='word',\n",
    "                     token_pattern=r'\\w{1,}', ngram_range=(1,2), use_idf=1,\n",
    "                     smooth_idf=1, sublinear_tf=1, stop_words='english')\n",
    "textFeatures = tfv.fit_transform(totalRev.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('float64'), dtype('float64'), dtype('O'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-7a4722f6c29b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m xtrain_sparse = sparse.hstack((textFeatures,\n\u001b[1;32m      6\u001b[0m                                \u001b[0mcategoricalTrainDataOHE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                totalRev[numeric_variables].values),format='csr')\n\u001b[0m",
      "\u001b[0;32m/Users/AnthonySpalvieriKruse/anaconda/lib/python2.7/site-packages/scipy/sparse/construct.pyc\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \"\"\"\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AnthonySpalvieriKruse/anaconda/lib/python2.7/site-packages/scipy/sparse/construct.pyc\u001b[0m in \u001b[0;36mbmat\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0mnnz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0mrow_offsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrow_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/AnthonySpalvieriKruse/anaconda/lib/python2.7/site-packages/scipy/sparse/sputils.pyc\u001b[0m in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no supported conversion for types: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('float64'), dtype('float64'), dtype('O'))"
     ]
    }
   ],
   "source": [
    "#This works, but it's only one of the columns\n",
    "#hmmm = sparse.hstack((np.array(totalRev.stars)[:,None], textFeatures))\n",
    "#X = sparse.hstack((textFeatures,totalRev[numeric_variables].values),format='csr')\n",
    "\n",
    "\n",
    "#Still broken; need to replace Nan's with 0's, also guarantee totalRev is all numeric\n",
    "xtrain_sparse = sparse.hstack((textFeatures,\n",
    "                               categoricalTrainDataOHE, \n",
    "                               totalRev[numeric_variables].values),format='csr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.72, nan, nan, nan, 1034.0, nan, nan, nan, 33.390792, 2.0, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, 14.0, nan, 19.0, nan, nan, nan,\n",
       "       nan, 8.0, 9.0, 1.0, 2.0, nan, nan, nan, nan, 116, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, 1.0, nan, 3.0, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, 1.0, nan, nan, nan, nan,\n",
       "       nan, 1.0, 6.0, 2.0, nan, 1.0, 1.0, 2.0, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, 1.0, nan, nan, nan, nan, nan, 5, nan, nan, nan,\n",
       "       nan, nan, nan, nan, 2.0, nan, 1.0, nan, nan, nan, nan, nan, nan,\n",
       "       nan, 12.0, nan, nan, nan, nan, nan, nan, -112.012504, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, 2.0, nan, nan, 1.0, 10.0, 11.0, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, 1.0, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, 5, nan, nan, Timestamp('2011-01-26 00:00:00'),\n",
       "       331.0, 4.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, 376.0, 322.0], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalRev[numeric_variables].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hmmm.A, columns=tfv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229907, 27)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229907, 779714)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x779714 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 122 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFeatures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    My wife took me here on my birthday for breakf...\n",
       "1    I have no idea why some people give bad review...\n",
       "2    love the gyro plate. Rice is so good and I als...\n",
       "3    Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4    General Manager Scott Petello is a good egg!!!...\n",
       "5    Quiessence is, simply put, beautiful.  Full wi...\n",
       "6    Drop what you're doing and drive here. After I...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalRev.text[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-29b5393a8f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtextFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalRev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tfv' is not defined"
     ]
    }
   ],
   "source": [
    "textFeatures = tfv.fit_transform(totalRev.text[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>awesome</th>\n",
       "      <th>came</th>\n",
       "      <th>delicious</th>\n",
       "      <th>didn</th>\n",
       "      <th>didn t</th>\n",
       "      <th>evening</th>\n",
       "      <th>food</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>menu</th>\n",
       "      <th>outside</th>\n",
       "      <th>place</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>try</th>\n",
       "      <th>ve</th>\n",
       "      <th>wait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.461280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272439</td>\n",
       "      <td>0.272439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242218</td>\n",
       "      <td>0.272439</td>\n",
       "      <td>0.217525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461280</td>\n",
       "      <td>0.272439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263062</td>\n",
       "      <td>0.263062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210038</td>\n",
       "      <td>0.263062</td>\n",
       "      <td>0.490825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210038</td>\n",
       "      <td>0.355625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372822</td>\n",
       "      <td>0.337040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466940</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>0.465111</td>\n",
       "      <td>0.465111</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>0.263492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155623</td>\n",
       "      <td>0.263492</td>\n",
       "      <td>0.392763</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.212444</td>\n",
       "      <td>0.212444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359699</td>\n",
       "      <td>0.287197</td>\n",
       "      <td>0.212444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212444</td>\n",
       "      <td>0.188878</td>\n",
       "      <td>0.212444</td>\n",
       "      <td>0.169623</td>\n",
       "      <td>0.355973</td>\n",
       "      <td>0.259633</td>\n",
       "      <td>0.359699</td>\n",
       "      <td>0.212444</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629815</td>\n",
       "      <td>0.629815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.279534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amazing   awesome      came  delicious      didn    didn t   evening  \\\n",
       "0  0.461280  0.000000  0.272439   0.272439  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.263062  0.263062   0.000000  0.000000  0.000000  0.263062   \n",
       "2  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.466940  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.000000  0.194909   0.194909  0.465111  0.465111  0.194909   \n",
       "6  0.212444  0.212444  0.000000   0.359699  0.000000  0.000000  0.000000   \n",
       "7  0.000000  0.000000  0.000000   0.000000  0.629815  0.629815  0.000000   \n",
       "8  0.350102  0.000000  0.000000   0.000000  0.350102  0.350102  0.350102   \n",
       "9  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       food      good     great      like      love      menu   outside  \\\n",
       "0  0.272439  0.000000  0.000000  0.242218  0.000000  0.242218  0.272439   \n",
       "1  0.000000  0.210038  0.263062  0.490825  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.623950  0.000000  0.000000  0.781464  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.781464  0.000000  0.000000   \n",
       "4  0.000000  0.372822  0.000000  0.415144  0.000000  0.000000  0.000000   \n",
       "5  0.194909  0.263492  0.000000  0.173288  0.000000  0.173288  0.000000   \n",
       "6  0.359699  0.287197  0.212444  0.000000  0.212444  0.188878  0.212444   \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8  0.000000  0.000000  0.350102  0.000000  0.000000  0.000000  0.350102   \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000   \n",
       "\n",
       "      place         s         t       try        ve      wait  \n",
       "0  0.217525  0.000000  0.196648  0.000000  0.461280  0.272439  \n",
       "1  0.210038  0.355625  0.000000  0.445402  0.000000  0.263062  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.623950  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.372822  0.337040  0.000000  0.466940  0.000000  \n",
       "5  0.155623  0.263492  0.392763  0.194909  0.000000  0.000000  \n",
       "6  0.169623  0.355973  0.259633  0.359699  0.212444  0.000000  \n",
       "7  0.000000  0.000000  0.454604  0.000000  0.000000  0.000000  \n",
       "8  0.279534  0.000000  0.252706  0.000000  0.000000  0.350102  \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(textFeatures.A, columns=tfv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                                         categories  \\\n",
      "0  rncjoVoEFUJGCUoC1JgnUA  [Accountants, Professional Services, Tax Servi...   \n",
      "1  0FNFSzCFP_rGUoJx8W7tJg                  [Sporting Goods, Bikes, Shopping]   \n",
      "2  3f_lyB6vFK48ukH6ScvLHg                                                 []   \n",
      "3  usAsSV36QmUej8--yvN-dg                                    [Food, Grocery]   \n",
      "4  PzOqRohWw7F7YEPBz6AubA                 [Food, Bagels, Delis, Restaurants]   \n",
      "\n",
      "          city                                       full_address   latitude  \\\n",
      "0       Peoria         8466 W Peoria Ave\\nSte 6\\nPeoria, AZ 85345  33.581867   \n",
      "1      Phoenix                  2149 W Wood Dr\\nPhoenix, AZ 85029  33.604054   \n",
      "2      Phoenix              1134 N Central Ave\\nPhoenix, AZ 85004  33.460526   \n",
      "3      Phoenix              845 W Southern Ave\\nPhoenix, AZ 85041  33.392210   \n",
      "4  Glendale Az  6520 W Happy Valley Rd\\nSte 101\\nGlendale Az, ...  33.712797   \n",
      "\n",
      "    longitude                          name neighborhoods  open  review_count  \\\n",
      "0 -112.241596     Peoria Income Tax Service            []  True             3   \n",
      "1 -112.105933                   Bike Doctor            []  True             5   \n",
      "2 -112.073933  Valley Permaculture Alliance            []  True             4   \n",
      "3 -112.085377                     Food City            []  True             5   \n",
      "4 -112.200264             Hot Bagels & Deli            []  True            14   \n",
      "\n",
      "   stars state      type  \n",
      "0    5.0    AZ  business  \n",
      "1    5.0    AZ  business  \n",
      "2    5.0    AZ  business  \n",
      "3    3.5    AZ  business  \n",
      "4    3.5    AZ  business  \n",
      "              business_id                                       checkin_info  \\\n",
      "0  KO9CpaSPOoqm0iCWm5scmg  {u'11-3': 17, u'10-1': 4, u'15-0': 2, u'15-3':...   \n",
      "1  oRqBAYtcBYZHXA7G8FlPaA  {u'0-5': 1, u'2-6': 2, u'2-5': 3, u'3-6': 1, u...   \n",
      "2  6cy2C9aBXUwkrh4bY1DApw  {u'8-5': 1, u'20-6': 1, u'15-3': 1, u'18-5': 1...   \n",
      "3  D0IB17N66FiyYDCzTlAI4A  {u'17-1': 1, u'10-5': 2, u'15-1': 1, u'20-0': ...   \n",
      "4  HLQGo3EaYVvAv22bONGkIw  {u'16-2': 1, u'14-5': 1, u'12-5': 2, u'15-4': ...   \n",
      "\n",
      "      type  \n",
      "0  checkin  \n",
      "1  checkin  \n",
      "2  checkin  \n",
      "3  checkin  \n",
      "4  checkin  \n",
      "   average_stars       name  review_count  type                 user_id  \\\n",
      "0            5.0        Jim             6  user  CR2y7yEm4X035ZMzrTtN9Q   \n",
      "1            1.0      Kelle             2  user  _9GXoHhdxc30ujPaQwh6Ew   \n",
      "2            5.0  Stephanie             2  user  8mM-nqxjg6pT04kwcjMbsw   \n",
      "3            5.0          T             2  user  Ch6CdTR2IVaVANr-RglMOg   \n",
      "4            1.0       Beth             1  user  NZrLmHRyiHmyT1JrfzkCOA   \n",
      "\n",
      "                                     votes  \n",
      "0  {u'funny': 0, u'useful': 7, u'cool': 0}  \n",
      "1  {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "2  {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "3  {u'funny': 0, u'useful': 2, u'cool': 0}  \n",
      "4  {u'funny': 0, u'useful': 0, u'cool': 0}  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>{u'funny': 0, u'useful': 5, u'cool': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>{u'funny': 0, u'useful': 1, u'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>{u'funny': 0, u'useful': 2, u'cool': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg 2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow 2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA 2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg 2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw 2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id                                    votes  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q  {u'funny': 0, u'useful': 5, u'cool': 2}  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ  {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg  {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
       "3  uZetl9T0NcROGOyFfughhg  {u'funny': 0, u'useful': 2, u'cool': 1}  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw  {u'funny': 0, u'useful': 0, u'cool': 0}  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print bsnes.head()\n",
    "print checkin.head()\n",
    "print user.head()\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43873\n",
      "45981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43873"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Is there user data for every review? No, will have to impute reviews w/ no reviewer data\n",
    "print user.user_id.unique().size\n",
    "print review.user_id.unique().size\n",
    "s1 = pd.merge(review, user, how='inner', on=[\"user_id\"])\n",
    "s1.user_id.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first:  0\n",
      "second:  0\n",
      "first:  0\n",
      "second:  3255\n",
      "first:  0\n",
      "second:  3255\n"
     ]
    }
   ],
   "source": [
    "#All reviews have a business to join to, and we have extra checkins that remain unused \n",
    "mutually_exclusive_elements(bsnes.business_id, review.business_id)\n",
    "mutually_exclusive_elements(checkin.business_id, bsnes.business_id)\n",
    "hm = mutually_exclusive_elements(checkin.business_id, review.business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([      u'business_id',              u'date',         u'review_id',\n",
      "                   u'stars',              u'text',            u'type_x',\n",
      "                 u'user_id',      u'useful_votes',     u'average_stars',\n",
      "               u'user_name', u'user_review_count',            u'type_y',\n",
      "              u'user_votes'],\n",
      "      dtype='object')\n",
      "Index([          u'business_id',                  u'date',\n",
      "                   u'review_id',                 u'stars',\n",
      "                        u'text',                u'type_x',\n",
      "                     u'user_id',          u'useful_votes',\n",
      "               u'average_stars',             u'user_name',\n",
      "           u'user_review_count',                u'type_y',\n",
      "                  u'user_votes',            u'categories',\n",
      "                        u'city',          u'full_address',\n",
      "                    u'latitude',             u'longitude',\n",
      "               u'business_name',         u'neighborhoods',\n",
      "                        u'open', u'business_review_count',\n",
      "              u'business_stars',                 u'state',\n",
      "                        u'type'],\n",
      "      dtype='object')\n",
      "Index([          u'business_id',                  u'date',\n",
      "                   u'review_id',                 u'stars',\n",
      "                        u'text',                u'type_x',\n",
      "                     u'user_id',          u'useful_votes',\n",
      "               u'average_stars',             u'user_name',\n",
      "           u'user_review_count',                u'type_y',\n",
      "                  u'user_votes',            u'categories',\n",
      "                        u'city',          u'full_address',\n",
      "                    u'latitude',             u'longitude',\n",
      "               u'business_name',         u'neighborhoods',\n",
      "                        u'open', u'business_review_count',\n",
      "              u'business_stars',                 u'state',\n",
      "                      u'type_x',          u'checkin_info',\n",
      "                      u'type_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Merge all the data into a single data frame\n",
    "\n",
    "\n",
    "\n",
    "#Apply text transformations on the review text\n",
    "#   Done, now it's a sparse matrix \n",
    "#Do oneHotEncoding or LabelEncoder stuff to categorical variables\n",
    "#   i. OHE takes all potential values for a category and turns them into their own binary feature\n",
    "#   ii. LE makes everything {1,2,...,N} for the # of categories, which is bad if ordinal relationship isn't intended\n",
    "#   iii. OHE is almost always better; only pitfalls are when there are lots of categories and space is an issue, but we\n",
    "#        can solve this by using a PCA on the OHE \n",
    "#Use Normalizer or StandardScaler (sklearn) on the linear variables\n",
    "#   i. I'm not sure why we need to do this.  Look this up \n",
    "#Perform a PCA or TruncatedSVD to reduce dimensionality (probably only necessary due to the text features)\n",
    "#Do feature selection; tons of ways to do this, choose one\n",
    "#Choose a model, train it, test it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
