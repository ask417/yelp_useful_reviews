{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.21.0\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "# SK-learn for feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "#Dimensionality Reduction \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Encoding categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import sys\n",
    "print sys.version_info[0]\n",
    "print pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def glue_jsons(user, review, bsnes, checkin):\n",
    "    #Convert all checkin times to their own columns \n",
    "    checkin = pd.concat([checkin.drop([\"checkin_info\"], axis=1), \n",
    "                         checkin[\"checkin_info\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "    user.rename(columns={'name': 'user_name', \n",
    "                          'review_count': 'user_review_count'}, inplace=True)\n",
    "\n",
    "    bsnes.rename(columns={'name': 'business_name', \n",
    "                      'review_count': 'business_review_count',\n",
    "                      'stars': 'business_stars'}, inplace=True)\n",
    "    \n",
    "    xtrain = pd.merge(review, user, how='left', on=['user_id'])\n",
    "    xtrain = pd.merge(xtrain, bsnes, how='left', on=['business_id'])\n",
    "    xtrain = pd.merge(xtrain, checkin, how='left', on=['business_id'])\n",
    "    del xtrain[\"type_x\"]\n",
    "    del xtrain[\"type_y\"]\n",
    "    del xtrain[\"neighborhoods\"]\n",
    "    xtrain.fillna(0, inplace=True)\n",
    "    return xtrain\n",
    "\n",
    "def mutually_exclusive_elements(set1, set2):\n",
    "    set1ExclusiveElements = set(set1).symmetric_difference(set2).intersection(set1)\n",
    "    set2ExclusiveElements = set(set1).symmetric_difference(set2).intersection(set2)\n",
    "    print \"first: \", len(set1ExclusiveElements)\n",
    "    print \"second: \", len(set2ExclusiveElements)\n",
    "    return {\"first\": set1ExclusiveElements, \"second\": set2ExclusiveElements}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsnes = pd.read_json(open(\"data/yelp_training_set_business.json\"), lines=True)\n",
    "checkin = pd.read_json(open(\"data/yelp_training_set_checkin.json\"), lines=True)\n",
    "user = pd.read_json(open(\"data/yelp_training_set_user.json\"), lines=True)\n",
    "review = pd.read_json(open(\"data/yelp_training_set_review.json\"), lines=True)\n",
    "\n",
    "bsnes_test = pd.read_json(open(\"data/yelp_test_set_business.json\"), lines=True)\n",
    "checkin_test = pd.read_json(open(\"data/yelp_test_set_checkin.json\"), lines=True)\n",
    "user_test = pd.read_json(open(\"data/yelp_test_set_user.json\"), lines=True)\n",
    "review_test = pd.read_json(open(\"data/yelp_test_set_review.json\"), lines=True)\n",
    "\n",
    "\n",
    "\n",
    "#Manually joining the user votes data from train into test where it's missing \n",
    "user = pd.concat([user.drop([\"votes\"], axis=1), user[\"votes\"].apply(pd.Series)], axis=1)\n",
    "#Need to merge user level vote data to the test data by joining on user_id and imputing the rest. \n",
    "user.rename(columns={ \"funny\": \"funny_votes_business\", \n",
    "                      \"useful\": \"useful_votes_business\",\n",
    "                      \"cool\": \"cool_votes_business\"}, inplace=True)\n",
    "\n",
    "user_test = pd.merge(user_test, user[[\"funny\",\"useful\",\"cool\"]], how='left', on['user_id'])\n",
    "\n",
    "xtest = glue_jsons(user_test, review_test, bsnes_test, checkin_test)\n",
    "xtrain = glue_jsons(user, review, bsnes, checkin)\n",
    "ytrain = [i['useful'] for i in review.votes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_variables = list(set(xtrain.select_dtypes(include=[\"object\",\"bool\"]).columns) - set([\"text\"]))\n",
    "numeric_variables = list(set(xtrain.columns) - set(categorical_variables) - set([\"text\", \"date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Encode Categorical Data\n",
    "from collections import defaultdict\n",
    "leD = defaultdict(LabelEncoder)\n",
    "oheD = defaultdict(OneHotEncoder)\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "#Brilliiant, this both fits, transforms, and retains the fit in the dictionary \n",
    "categoricalTrainDataLE = xtrain[categorical_variables].apply(lambda x: leD[x.name].fit_transform(x))\n",
    "ohe = ohe.fit(categoricalTrainDataLE)\n",
    "categoricalTrainDataOHE = ohe.transform(categoricalTrainDataLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0053496 ,  0.03917613,  0.02096237,  0.01549227,  0.01063187,\n",
       "        0.00807126,  0.00731319,  0.00690965,  0.00494638,  0.00459248,\n",
       "        0.00402336,  0.00386649,  0.0028704 ,  0.00268211,  0.00247562,\n",
       "        0.00240892,  0.0022879 ,  0.00212588,  0.00199901,  0.00193747,\n",
       "        0.00189519,  0.00185844,  0.00182885,  0.00177708,  0.00166503,\n",
       "        0.00163475,  0.00161188,  0.00160095,  0.0015648 ,  0.00152245,\n",
       "        0.00146319,  0.00144717,  0.00143393,  0.00142274,  0.00141463,\n",
       "        0.00139121,  0.00135745,  0.00131679,  0.00131298,  0.0012835 ,\n",
       "        0.00123112,  0.00116519,  0.00113645,  0.00112108,  0.00111705,\n",
       "        0.00111215,  0.00108944,  0.00104616,  0.0010023 ,  0.00099707,\n",
       "        0.00099574,  0.00098065,  0.00096262,  0.00094827,  0.00093895,\n",
       "        0.00093573,  0.00092838,  0.00092367,  0.00091658,  0.00091342,\n",
       "        0.00090197,  0.00086907,  0.00086566,  0.00085337,  0.00085028,\n",
       "        0.00084086,  0.00083482,  0.00083065,  0.00082784,  0.00080849,\n",
       "        0.00080422,  0.00079822,  0.00079113,  0.00078985,  0.00077996,\n",
       "        0.00077267,  0.00076697,  0.00076204,  0.00075643,  0.00074522,\n",
       "        0.00073489,  0.00073331,  0.00073274,  0.00072902,  0.00071906,\n",
       "        0.00071755,  0.00070998,  0.00070645,  0.00070154,  0.00069643,\n",
       "        0.00069213,  0.0006896 ,  0.00068811,  0.00068591,  0.00068528,\n",
       "        0.00068332,  0.00068005,  0.00067345,  0.00067195,  0.00066954,\n",
       "        0.00066517,  0.0006612 ,  0.00064803,  0.00064724,  0.00064413,\n",
       "        0.0006401 ,  0.00063782,  0.00063676,  0.00063398,  0.00063294,\n",
       "        0.00062896,  0.00062746,  0.00062115,  0.00061637,  0.00061098,\n",
       "        0.00060489,  0.00060268,  0.0005985 ,  0.00059812,  0.00059289,\n",
       "        0.00058913,  0.00058743,  0.00058468,  0.00058046,  0.00057791,\n",
       "        0.00057574,  0.0005679 ,  0.00056478,  0.00056332,  0.00056184,\n",
       "        0.0005596 ,  0.00055711,  0.00055391,  0.00055337,  0.00055085,\n",
       "        0.00055   ,  0.00054822,  0.0005446 ,  0.0005429 ,  0.00054163,\n",
       "        0.00054032,  0.00053928,  0.00053562,  0.00053073,  0.00052883,\n",
       "        0.00052563,  0.00052271,  0.00051912,  0.00051617,  0.00051239,\n",
       "        0.00051026,  0.00050654,  0.00050522,  0.00050043,  0.00049678,\n",
       "        0.00049619,  0.00049242,  0.00049049,  0.00048863,  0.00048692,\n",
       "        0.00048348,  0.00048267,  0.00048078,  0.00047938,  0.00047701,\n",
       "        0.00047395,  0.00047146,  0.00047008,  0.00046825,  0.00046501,\n",
       "        0.00046072,  0.00045995,  0.00045858,  0.00045708,  0.00045671,\n",
       "        0.00045267,  0.00045077,  0.00045024,  0.00044639,  0.00044519,\n",
       "        0.00044215,  0.00043989,  0.00043897,  0.00043617,  0.00043493,\n",
       "        0.00043356,  0.00043201,  0.00042823,  0.00042746,  0.00042521,\n",
       "        0.00042422,  0.00042228,  0.00041834,  0.00041545,  0.00041294,\n",
       "        0.00041055,  0.00040799,  0.0004056 ,  0.00040469,  0.00039957])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoriesSvd = TruncatedSVD(n_components=200)\n",
    "categoriesSvd.fit(categoricalTrainDataOHE)\n",
    "categoricalTrainDataOHESvd = categoriesSvd.transform(categoricalTrainDataOHE)\n",
    "categoriesSvd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28343742376465231"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(categoriesSvd.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00085878,  0.00149577,  0.00111431,  0.0009416 ,  0.00088758,\n",
       "        0.00084887,  0.00078751,  0.00077761,  0.00071704,  0.00069703,\n",
       "        0.0006692 ,  0.00063505,  0.00060891,  0.0006009 ,  0.00057535,\n",
       "        0.00056297,  0.00055195,  0.00051869,  0.00051556,  0.00050494,\n",
       "        0.00049736,  0.00049136,  0.00048019,  0.00048008,  0.00047129,\n",
       "        0.00046275,  0.00045498,  0.00044752,  0.00044104,  0.00043785,\n",
       "        0.00042467,  0.00042049,  0.00041108,  0.00040786,  0.00039945,\n",
       "        0.00039693,  0.00039319,  0.00039047,  0.00038647,  0.00038207,\n",
       "        0.00037908,  0.00037457,  0.000371  ,  0.00036581,  0.00035883,\n",
       "        0.00035698,  0.00035336,  0.00035154,  0.00034848,  0.00034655,\n",
       "        0.00034522,  0.00034356,  0.00033966,  0.00033868,  0.00033509,\n",
       "        0.00033408,  0.00033071,  0.00032959,  0.00032559,  0.00032493,\n",
       "        0.00032147,  0.00032108,  0.00031595,  0.00031459,  0.00031264,\n",
       "        0.00031051,  0.00030727,  0.00030563,  0.00030402,  0.00030258,\n",
       "        0.00029987,  0.0002981 ,  0.00029478,  0.00029451,  0.00029383,\n",
       "        0.00029029,  0.00028876,  0.00028692,  0.00028546,  0.0002836 ,\n",
       "        0.00028215,  0.00027989,  0.00027698,  0.00027573,  0.00027457,\n",
       "        0.00027385,  0.00027063,  0.00026937,  0.00026876,  0.00026697,\n",
       "        0.00026664,  0.00026428,  0.00026277,  0.00026014,  0.00025925,\n",
       "        0.00025844,  0.00025706,  0.00025564,  0.00025536,  0.0002535 ,\n",
       "        0.00025145,  0.00024958,  0.00024921,  0.00024774,  0.00024692,\n",
       "        0.00024489,  0.00024384,  0.00024281,  0.00024149,  0.00024042,\n",
       "        0.00023964,  0.00023641,  0.00023578,  0.00023423,  0.00023312,\n",
       "        0.00023237,  0.00023141,  0.00022923,  0.00022853,  0.00022696])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfv = TfidfVectorizer(min_df=3, max_features=None,\n",
    "                      strip_accents='unicode', analyzer='word',\n",
    "                     token_pattern=r'\\w{1,}', ngram_range=(1,2), use_idf=1,\n",
    "                     smooth_idf=1, sublinear_tf=1, stop_words='english')\n",
    "textFeatures = tfv.fit_transform(xtrain.text)\n",
    "svd = TruncatedSVD(n_components=120)\n",
    "svd.fit(textFeatures)\n",
    "textFeaturesSVD = svd.transform(textFeatures)\n",
    "svd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(svd.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(xtrain[numeric_variables])\n",
    "xtrain[numeric_variables] = scaler.transform(xtrain[numeric_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10822675 -0.00035359 -0.03582709 ...,  0.00903369  0.00539432\n",
      "  -0.00918362]\n",
      " [ 0.11138171 -0.02405241 -0.01843058 ..., -0.01014245 -0.01171632\n",
      "   0.01615613]\n",
      " [ 0.04084059  0.02322308 -0.01916287 ...,  0.03630289 -0.00520356\n",
      "   0.01950582]\n",
      " ..., \n",
      " [ 0.08576055  0.12638387  0.00428202 ..., -0.02038182 -0.02039968\n",
      "   0.03669999]\n",
      " [ 0.07850521  0.00916698 -0.0178492  ..., -0.01431194 -0.00397014\n",
      "  -0.02569238]\n",
      " [ 0.01991111 -0.0027785   0.02411887 ...,  0.02361712 -0.06427272\n",
      "  -0.01346345]]\n",
      "(229907, 120)\n",
      "(229907, 200)\n",
      "(229907, 178)\n"
     ]
    }
   ],
   "source": [
    "print textFeaturesSVD\n",
    "print textFeaturesSVD.shape\n",
    "print categoricalTrainDataOHESvd.shape\n",
    "print xtrain[numeric_variables].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stack features like a ballerrrrr\n",
    "# xtrain_sparse = sparse.hstack((textFeaturesSVD,\n",
    "#                                categoricalTrainDataOHESvd, \n",
    "#                                xtrain[numeric_variables].values),format='csr')\n",
    "\n",
    "#No longer doing sparse matrices, so this is kosher \n",
    "xtrain_joined = np.hstack((textFeaturesSVD,\n",
    "                               categoricalTrainDataOHESvd, \n",
    "                               xtrain[numeric_variables].values))\n",
    "\n",
    "del textFeatures\n",
    "del textFeaturesSVD\n",
    "del categoricalTrainDataOHESvd\n",
    "del xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229907, 498)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "rfc.fit(xtrain_joined, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3, 7, 1, 0, 1, 3, 1, 2, 2, 1, 2, 4, 0, 6, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.predict(xtrain_joined[2:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                                         categories  \\\n",
      "0  rncjoVoEFUJGCUoC1JgnUA  [Accountants, Professional Services, Tax Servi...   \n",
      "1  0FNFSzCFP_rGUoJx8W7tJg                  [Sporting Goods, Bikes, Shopping]   \n",
      "2  3f_lyB6vFK48ukH6ScvLHg                                                 []   \n",
      "3  usAsSV36QmUej8--yvN-dg                                    [Food, Grocery]   \n",
      "4  PzOqRohWw7F7YEPBz6AubA                 [Food, Bagels, Delis, Restaurants]   \n",
      "\n",
      "          city                                       full_address   latitude  \\\n",
      "0       Peoria         8466 W Peoria Ave\\nSte 6\\nPeoria, AZ 85345  33.581867   \n",
      "1      Phoenix                  2149 W Wood Dr\\nPhoenix, AZ 85029  33.604054   \n",
      "2      Phoenix              1134 N Central Ave\\nPhoenix, AZ 85004  33.460526   \n",
      "3      Phoenix              845 W Southern Ave\\nPhoenix, AZ 85041  33.392210   \n",
      "4  Glendale Az  6520 W Happy Valley Rd\\nSte 101\\nGlendale Az, ...  33.712797   \n",
      "\n",
      "    longitude                          name neighborhoods  open  review_count  \\\n",
      "0 -112.241596     Peoria Income Tax Service            []  True             3   \n",
      "1 -112.105933                   Bike Doctor            []  True             5   \n",
      "2 -112.073933  Valley Permaculture Alliance            []  True             4   \n",
      "3 -112.085377                     Food City            []  True             5   \n",
      "4 -112.200264             Hot Bagels & Deli            []  True            14   \n",
      "\n",
      "   stars state      type  \n",
      "0    5.0    AZ  business  \n",
      "1    5.0    AZ  business  \n",
      "2    5.0    AZ  business  \n",
      "3    3.5    AZ  business  \n",
      "4    3.5    AZ  business  \n",
      "              business_id                                       checkin_info  \\\n",
      "0  KO9CpaSPOoqm0iCWm5scmg  {u'11-3': 17, u'10-1': 4, u'15-0': 2, u'15-3':...   \n",
      "1  oRqBAYtcBYZHXA7G8FlPaA  {u'0-5': 1, u'2-6': 2, u'2-5': 3, u'3-6': 1, u...   \n",
      "2  6cy2C9aBXUwkrh4bY1DApw  {u'8-5': 1, u'20-6': 1, u'15-3': 1, u'18-5': 1...   \n",
      "3  D0IB17N66FiyYDCzTlAI4A  {u'17-1': 1, u'10-5': 2, u'15-1': 1, u'20-0': ...   \n",
      "4  HLQGo3EaYVvAv22bONGkIw  {u'16-2': 1, u'14-5': 1, u'12-5': 2, u'15-4': ...   \n",
      "\n",
      "      type  \n",
      "0  checkin  \n",
      "1  checkin  \n",
      "2  checkin  \n",
      "3  checkin  \n",
      "4  checkin  \n",
      "   average_stars       name  review_count  type                 user_id  \\\n",
      "0            5.0        Jim             6  user  CR2y7yEm4X035ZMzrTtN9Q   \n",
      "1            1.0      Kelle             2  user  _9GXoHhdxc30ujPaQwh6Ew   \n",
      "2            5.0  Stephanie             2  user  8mM-nqxjg6pT04kwcjMbsw   \n",
      "3            5.0          T             2  user  Ch6CdTR2IVaVANr-RglMOg   \n",
      "4            1.0       Beth             1  user  NZrLmHRyiHmyT1JrfzkCOA   \n",
      "\n",
      "                                     votes  \n",
      "0  {u'funny': 0, u'useful': 7, u'cool': 0}  \n",
      "1  {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "2  {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "3  {u'funny': 0, u'useful': 2, u'cool': 0}  \n",
      "4  {u'funny': 0, u'useful': 0, u'cool': 0}  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>{u'funny': 0, u'useful': 5, u'cool': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>{u'funny': 0, u'useful': 1, u'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>{u'funny': 0, u'useful': 2, u'cool': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg 2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow 2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA 2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg 2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw 2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id                                    votes  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q  {u'funny': 0, u'useful': 5, u'cool': 2}  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ  {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg  {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
       "3  uZetl9T0NcROGOyFfughhg  {u'funny': 0, u'useful': 2, u'cool': 1}  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw  {u'funny': 0, u'useful': 0, u'cool': 0}  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print bsnes.head()\n",
    "print checkin.head()\n",
    "print user.head()\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first:  0\n",
      "second:  0\n",
      "first:  0\n",
      "second:  3255\n",
      "first:  0\n",
      "second:  3255\n"
     ]
    }
   ],
   "source": [
    "#All reviews have a business to join to, and we have extra checkins that remain unused \n",
    "mutually_exclusive_elements(bsnes.business_id, review.business_id)\n",
    "mutually_exclusive_elements(checkin.business_id, bsnes.business_id)\n",
    "hm = mutually_exclusive_elements(checkin.business_id, review.business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([      u'business_id',              u'date',         u'review_id',\n",
      "                   u'stars',              u'text',            u'type_x',\n",
      "                 u'user_id',      u'useful_votes',     u'average_stars',\n",
      "               u'user_name', u'user_review_count',            u'type_y',\n",
      "              u'user_votes'],\n",
      "      dtype='object')\n",
      "Index([          u'business_id',                  u'date',\n",
      "                   u'review_id',                 u'stars',\n",
      "                        u'text',                u'type_x',\n",
      "                     u'user_id',          u'useful_votes',\n",
      "               u'average_stars',             u'user_name',\n",
      "           u'user_review_count',                u'type_y',\n",
      "                  u'user_votes',            u'categories',\n",
      "                        u'city',          u'full_address',\n",
      "                    u'latitude',             u'longitude',\n",
      "               u'business_name',         u'neighborhoods',\n",
      "                        u'open', u'business_review_count',\n",
      "              u'business_stars',                 u'state',\n",
      "                        u'type'],\n",
      "      dtype='object')\n",
      "Index([          u'business_id',                  u'date',\n",
      "                   u'review_id',                 u'stars',\n",
      "                        u'text',                u'type_x',\n",
      "                     u'user_id',          u'useful_votes',\n",
      "               u'average_stars',             u'user_name',\n",
      "           u'user_review_count',                u'type_y',\n",
      "                  u'user_votes',            u'categories',\n",
      "                        u'city',          u'full_address',\n",
      "                    u'latitude',             u'longitude',\n",
      "               u'business_name',         u'neighborhoods',\n",
      "                        u'open', u'business_review_count',\n",
      "              u'business_stars',                 u'state',\n",
      "                      u'type_x',          u'checkin_info',\n",
      "                      u'type_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Merge all the data into a single data frame\n",
    "\n",
    "\n",
    "\n",
    "#Apply text transformations on the review text\n",
    "#   Done, now it's a sparse matrix \n",
    "#Do oneHotEncoding or LabelEncoder stuff to categorical variables\n",
    "#   i. OHE takes all potential values for a category and turns them into their own binary feature\n",
    "#   ii. LE makes everything {1,2,...,N} for the # of categories, which is bad if ordinal relationship isn't intended\n",
    "#   iii. OHE is almost always better; only pitfalls are when there are lots of categories and space is an issue, but we\n",
    "#        can solve this by using a PCA on the OHE \n",
    "#Use Normalizer or StandardScaler (sklearn) on the linear variables\n",
    "#   i. I'm not sure why we need to do this.  Look this up \n",
    "#Perform a PCA or TruncatedSVD to reduce dimensionality (probably only necessary due to the text features)\n",
    "#Do feature selection; tons of ways to do this, choose one\n",
    "#Choose a model, train it, test it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest_le = xtest[categorical_variables].apply(lambda x: leD[x.name].transform(x))\n",
    "xtest_ohe = ohe.transform(xtest_le)\n",
    "xtest_ohe = categoriesSvd.transform(xtest_ohe)\n",
    "test_text_features = tfv.transform(xtest.text)\n",
    "test_text_features = svd.transform(test_text_features)\n",
    "xtest[numeric_variables] = scaler.transform(xtest[numeric_variables])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
