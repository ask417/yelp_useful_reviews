{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.21.0\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "# SK-learn for feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "#Dimensionality Reduction \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Encoding categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import sys\n",
    "print sys.version_info[0]\n",
    "print pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mutually_exclusive_elements(set1, set2):\n",
    "    set1ExclusiveElements = set(set1).symmetric_difference(set2).intersection(set1)\n",
    "    set2ExclusiveElements = set(set1).symmetric_difference(set2).intersection(set2)\n",
    "    print \"first: \", len(set1ExclusiveElements)\n",
    "    print \"second: \", len(set2ExclusiveElements)\n",
    "    return {\"first\": set1ExclusiveElements, \"second\": set2ExclusiveElements}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsnes = pd.read_json(open(\"data/yelp_training_set_business.json\"), lines=True)\n",
    "checkin = pd.read_json(open(\"data/yelp_training_set_checkin.json\"), lines=True)\n",
    "user = pd.read_json(open(\"data/yelp_training_set_user.json\"), lines=True)\n",
    "review = pd.read_json(open(\"data/yelp_training_set_review.json\"), lines=True)\n",
    "\n",
    "user = pd.concat([user.drop([\"votes\"], axis=1), user[\"votes\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "#Convert all checkin times to their own columns \n",
    "checkin = pd.concat([checkin.drop([\"checkin_info\"], axis=1), checkin[\"checkin_info\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "#Need to merge user level vote data to the test data by joining on user_id and imputing the rest. \n",
    "bsnes.rename(columns={'name': 'business_name', \n",
    "                      'review_count': 'business_review_count',\n",
    "                      'stars': 'business_stars'}, inplace=True)\n",
    "\n",
    "user.rename(columns={'name': 'user_name', \n",
    "                      'review_count': 'user_review_count',\n",
    "                      \"funny\": \"funny_votes_business\", \n",
    "                      \"useful\": \"useful_votes_business\",\n",
    "                      \"cool\": \"cool_votes_business\"}, inplace=True)\n",
    "\n",
    "review.rename(columns={'votes': 'useful_votes'}, inplace=True)\n",
    "\n",
    "xtrain = pd.merge(review, user, how='left', on=['user_id'])\n",
    "xtrain = pd.merge(xtrain, bsnes, how='left', on=['business_id'])\n",
    "xtrain = pd.merge(xtrain, checkin, how='left', on=['business_id'])\n",
    "xtrain.useful_votes = [i['useful'] for i in review.useful_votes]\n",
    "ytrain = xtrain.useful_votes\n",
    "del xtrain[\"useful_votes\"]\n",
    "del xtrain[\"type_x\"]\n",
    "del xtrain[\"type_y\"]\n",
    "del xtrain[\"neighborhoods\"]\n",
    "xtrain.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_variables = list(set(xtrain.select_dtypes(include=[\"object\",\"bool\"]).columns) - set([\"text\"]))\n",
    "numeric_variables = list(set(xtrain.columns) - set(categorical_variables) - set([\"text\", \"date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Encode Categorical Data\n",
    "from collections import defaultdict\n",
    "leD = defaultdict(LabelEncoder)\n",
    "oheD = defaultdict(OneHotEncoder)\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "#Brilliiant, this both fits, transforms, and retains the fit in the dictionary \n",
    "categoricalTrainDataLE = xtrain[categorical_variables].apply(lambda x: leD[x.name].fit_transform(x))\n",
    "ohe = ohe.fit(categoricalTrainDataLE)\n",
    "categoricalTrainDataOHE = ohe.transform(categoricalTrainDataLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categoriesSvd = TruncatedSVD(n_components=200)\n",
    "categoriesSvd.fit(categoricalTrainDataOHE)\n",
    "categoricalTrainDataOHESvd = categoriesSvd.transform(categoricalTrainDataOHE)\n",
    "categoriesSvd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(categoriesSvd.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=3, max_features=None,\n",
    "                      strip_accents='unicode', analyzer='word',\n",
    "                     token_pattern=r'\\w{1,}', ngram_range=(1,2), use_idf=1,\n",
    "                     smooth_idf=1, sublinear_tf=1, stop_words='english')\n",
    "textFeatures = tfv.fit_transform(xtrain.text)\n",
    "svd = TruncatedSVD(n_components=120)\n",
    "svd.fit(textFeatures)\n",
    "textFeaturesSVD = svd.transform(textFeatures)\n",
    "svd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(svd.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(xtrain[numeric_variables])\n",
    "xtrain[numeric_variables] = scaler.transform(xtrain[numeric_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10822675 -0.00035359 -0.03582709 ...,  0.00903369  0.00539432\n",
      "  -0.00918362]\n",
      " [ 0.11138171 -0.02405241 -0.01843058 ..., -0.01014245 -0.01171632\n",
      "   0.01615613]\n",
      " [ 0.04084059  0.02322308 -0.01916287 ...,  0.03630289 -0.00520356\n",
      "   0.01950582]\n",
      " ..., \n",
      " [ 0.08576055  0.12638387  0.00428202 ..., -0.02038182 -0.02039968\n",
      "   0.03669999]\n",
      " [ 0.07850521  0.00916698 -0.0178492  ..., -0.01431194 -0.00397014\n",
      "  -0.02569238]\n",
      " [ 0.01991111 -0.0027785   0.02411887 ...,  0.02361712 -0.06427272\n",
      "  -0.01346345]]\n",
      "(229907, 120)\n",
      "(229907, 200)\n",
      "(229907, 178)\n"
     ]
    }
   ],
   "source": [
    "print textFeaturesSVD\n",
    "print textFeaturesSVD.shape\n",
    "print categoricalTrainDataOHESvd.shape\n",
    "print xtrain[numeric_variables].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stack features like a ballerrrrr\n",
    "# xtrain_sparse = sparse.hstack((textFeaturesSVD,\n",
    "#                                categoricalTrainDataOHESvd, \n",
    "#                                xtrain[numeric_variables].values),format='csr')\n",
    "\n",
    "#No longer doing sparse matrices, so this is kosher \n",
    "xtrain_joined = np.hstack((textFeaturesSVD,\n",
    "                               categoricalTrainDataOHESvd, \n",
    "                               xtrain[numeric_variables].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229907, 498)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=2, n_jobs=-1)\n",
    "rfc.fit(xtrain_joined, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229907, 779714)\n",
      "(229907, 316529)\n",
      "(229907, 178)\n",
      "(229907, 1096421)\n",
      "  (0, 482)\t0.0812243340281\n",
      "  (0, 2475)\t0.0501251182175\n",
      "  (0, 2631)\t0.112597709649\n",
      "  (0, 10220)\t0.0775195567373\n",
      "  (0, 10545)\t0.0521383900644\n",
      "  (0, 10605)\t0.0744493394891\n",
      "  (0, 11467)\t0.0432799112168\n",
      "  (0, 11819)\t0.103073283617\n",
      "  (0, 12069)\t0.0791233926149\n",
      "  (0, 12265)\t0.0674240526336\n",
      "  (0, 12272)\t0.112597709649\n",
      "  (0, 36814)\t0.0438607006676\n",
      "  (0, 36835)\t0.0816543266098\n",
      "  (0, 47696)\t0.0331906540948\n",
      "  (0, 48120)\t0.0909184079132\n",
      "  (0, 51028)\t0.0677673854462\n",
      "  (0, 51804)\t0.171855176722\n",
      "  (0, 51805)\t0.0729746170426\n",
      "  (0, 52938)\t0.0488439684356\n",
      "  (0, 53093)\t0.09217563283\n",
      "  (0, 62063)\t0.038829741185\n",
      "  (0, 62527)\t0.099545469434\n",
      "  (0, 67769)\t0.0491657067593\n",
      "  (0, 67990)\t0.112597709649\n",
      "  (0, 68669)\t0.101500435813\n",
      "  :\t:\n",
      "  (0, 1096396)\t-0.191088257068\n",
      "  (0, 1096397)\t-0.153391205149\n",
      "  (0, 1096398)\t-0.170857969492\n",
      "  (0, 1096399)\t-0.177459884754\n",
      "  (0, 1096400)\t-0.195334284418\n",
      "  (0, 1096401)\t-0.192975646388\n",
      "  (0, 1096402)\t-0.19577211688\n",
      "  (0, 1096403)\t-0.261012197573\n",
      "  (0, 1096404)\t0.376654927334\n",
      "  (0, 1096405)\t-0.077956953195\n",
      "  (0, 1096406)\t-0.0754919956309\n",
      "  (0, 1096407)\t-0.0722779299306\n",
      "  (0, 1096408)\t-0.0762970227163\n",
      "  (0, 1096409)\t-0.0718957289923\n",
      "  (0, 1096410)\t-0.0766291061104\n",
      "  (0, 1096411)\t-0.0797586769854\n",
      "  (0, 1096412)\t-0.0944948709212\n",
      "  (0, 1096413)\t-0.120963394742\n",
      "  (0, 1096414)\t-0.0761336712615\n",
      "  (0, 1096415)\t-0.0809747733267\n",
      "  (0, 1096416)\t-0.0796690785324\n",
      "  (0, 1096417)\t-0.0936950100604\n",
      "  (0, 1096418)\t-0.105483953506\n",
      "  (0, 1096419)\t-0.567839997444\n",
      "  (0, 1096420)\t-0.268918533634\n"
     ]
    }
   ],
   "source": [
    "print textFeatures.shape\n",
    "print categoricalTrainDataOHE.shape\n",
    "print xtrain[numeric_variables].shape\n",
    "print xtrain_sparse.shape\n",
    "print xtrain_sparse[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>awesome</th>\n",
       "      <th>came</th>\n",
       "      <th>delicious</th>\n",
       "      <th>didn</th>\n",
       "      <th>didn t</th>\n",
       "      <th>evening</th>\n",
       "      <th>food</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>menu</th>\n",
       "      <th>outside</th>\n",
       "      <th>place</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>try</th>\n",
       "      <th>ve</th>\n",
       "      <th>wait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.461280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272439</td>\n",
       "      <td>0.272439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242218</td>\n",
       "      <td>0.272439</td>\n",
       "      <td>0.217525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461280</td>\n",
       "      <td>0.272439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263062</td>\n",
       "      <td>0.263062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210038</td>\n",
       "      <td>0.263062</td>\n",
       "      <td>0.490825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210038</td>\n",
       "      <td>0.355625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372822</td>\n",
       "      <td>0.337040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466940</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>0.465111</td>\n",
       "      <td>0.465111</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>0.263492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155623</td>\n",
       "      <td>0.263492</td>\n",
       "      <td>0.392763</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.212444</td>\n",
       "      <td>0.212444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359699</td>\n",
       "      <td>0.287197</td>\n",
       "      <td>0.212444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212444</td>\n",
       "      <td>0.188878</td>\n",
       "      <td>0.212444</td>\n",
       "      <td>0.169623</td>\n",
       "      <td>0.355973</td>\n",
       "      <td>0.259633</td>\n",
       "      <td>0.359699</td>\n",
       "      <td>0.212444</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629815</td>\n",
       "      <td>0.629815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.279534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amazing   awesome      came  delicious      didn    didn t   evening  \\\n",
       "0  0.461280  0.000000  0.272439   0.272439  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.263062  0.263062   0.000000  0.000000  0.000000  0.263062   \n",
       "2  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.466940  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.000000  0.194909   0.194909  0.465111  0.465111  0.194909   \n",
       "6  0.212444  0.212444  0.000000   0.359699  0.000000  0.000000  0.000000   \n",
       "7  0.000000  0.000000  0.000000   0.000000  0.629815  0.629815  0.000000   \n",
       "8  0.350102  0.000000  0.000000   0.000000  0.350102  0.350102  0.350102   \n",
       "9  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       food      good     great      like      love      menu   outside  \\\n",
       "0  0.272439  0.000000  0.000000  0.242218  0.000000  0.242218  0.272439   \n",
       "1  0.000000  0.210038  0.263062  0.490825  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.623950  0.000000  0.000000  0.781464  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.781464  0.000000  0.000000   \n",
       "4  0.000000  0.372822  0.000000  0.415144  0.000000  0.000000  0.000000   \n",
       "5  0.194909  0.263492  0.000000  0.173288  0.000000  0.173288  0.000000   \n",
       "6  0.359699  0.287197  0.212444  0.000000  0.212444  0.188878  0.212444   \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8  0.000000  0.000000  0.350102  0.000000  0.000000  0.000000  0.350102   \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000   \n",
       "\n",
       "      place         s         t       try        ve      wait  \n",
       "0  0.217525  0.000000  0.196648  0.000000  0.461280  0.272439  \n",
       "1  0.210038  0.355625  0.000000  0.445402  0.000000  0.263062  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.623950  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.372822  0.337040  0.000000  0.466940  0.000000  \n",
       "5  0.155623  0.263492  0.392763  0.194909  0.000000  0.000000  \n",
       "6  0.169623  0.355973  0.259633  0.359699  0.212444  0.000000  \n",
       "7  0.000000  0.000000  0.454604  0.000000  0.000000  0.000000  \n",
       "8  0.279534  0.000000  0.252706  0.000000  0.000000  0.350102  \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(textFeatures.A, columns=tfv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                                         categories  \\\n",
      "0  rncjoVoEFUJGCUoC1JgnUA  [Accountants, Professional Services, Tax Servi...   \n",
      "1  0FNFSzCFP_rGUoJx8W7tJg                  [Sporting Goods, Bikes, Shopping]   \n",
      "2  3f_lyB6vFK48ukH6ScvLHg                                                 []   \n",
      "3  usAsSV36QmUej8--yvN-dg                                    [Food, Grocery]   \n",
      "4  PzOqRohWw7F7YEPBz6AubA                 [Food, Bagels, Delis, Restaurants]   \n",
      "\n",
      "          city                                       full_address   latitude  \\\n",
      "0       Peoria         8466 W Peoria Ave\\nSte 6\\nPeoria, AZ 85345  33.581867   \n",
      "1      Phoenix                  2149 W Wood Dr\\nPhoenix, AZ 85029  33.604054   \n",
      "2      Phoenix              1134 N Central Ave\\nPhoenix, AZ 85004  33.460526   \n",
      "3      Phoenix              845 W Southern Ave\\nPhoenix, AZ 85041  33.392210   \n",
      "4  Glendale Az  6520 W Happy Valley Rd\\nSte 101\\nGlendale Az, ...  33.712797   \n",
      "\n",
      "    longitude                          name neighborhoods  open  review_count  \\\n",
      "0 -112.241596     Peoria Income Tax Service            []  True             3   \n",
      "1 -112.105933                   Bike Doctor            []  True             5   \n",
      "2 -112.073933  Valley Permaculture Alliance            []  True             4   \n",
      "3 -112.085377                     Food City            []  True             5   \n",
      "4 -112.200264             Hot Bagels & Deli            []  True            14   \n",
      "\n",
      "   stars state      type  \n",
      "0    5.0    AZ  business  \n",
      "1    5.0    AZ  business  \n",
      "2    5.0    AZ  business  \n",
      "3    3.5    AZ  business  \n",
      "4    3.5    AZ  business  \n",
      "              business_id                                       checkin_info  \\\n",
      "0  KO9CpaSPOoqm0iCWm5scmg  {u'11-3': 17, u'10-1': 4, u'15-0': 2, u'15-3':...   \n",
      "1  oRqBAYtcBYZHXA7G8FlPaA  {u'0-5': 1, u'2-6': 2, u'2-5': 3, u'3-6': 1, u...   \n",
      "2  6cy2C9aBXUwkrh4bY1DApw  {u'8-5': 1, u'20-6': 1, u'15-3': 1, u'18-5': 1...   \n",
      "3  D0IB17N66FiyYDCzTlAI4A  {u'17-1': 1, u'10-5': 2, u'15-1': 1, u'20-0': ...   \n",
      "4  HLQGo3EaYVvAv22bONGkIw  {u'16-2': 1, u'14-5': 1, u'12-5': 2, u'15-4': ...   \n",
      "\n",
      "      type  \n",
      "0  checkin  \n",
      "1  checkin  \n",
      "2  checkin  \n",
      "3  checkin  \n",
      "4  checkin  \n",
      "   average_stars       name  review_count  type                 user_id  \\\n",
      "0            5.0        Jim             6  user  CR2y7yEm4X035ZMzrTtN9Q   \n",
      "1            1.0      Kelle             2  user  _9GXoHhdxc30ujPaQwh6Ew   \n",
      "2            5.0  Stephanie             2  user  8mM-nqxjg6pT04kwcjMbsw   \n",
      "3            5.0          T             2  user  Ch6CdTR2IVaVANr-RglMOg   \n",
      "4            1.0       Beth             1  user  NZrLmHRyiHmyT1JrfzkCOA   \n",
      "\n",
      "                                     votes  \n",
      "0  {u'funny': 0, u'useful': 7, u'cool': 0}  \n",
      "1  {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "2  {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "3  {u'funny': 0, u'useful': 2, u'cool': 0}  \n",
      "4  {u'funny': 0, u'useful': 0, u'cool': 0}  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>{u'funny': 0, u'useful': 5, u'cool': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>{u'funny': 0, u'useful': 1, u'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>{u'funny': 0, u'useful': 2, u'cool': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg 2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow 2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA 2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg 2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw 2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id                                    votes  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q  {u'funny': 0, u'useful': 5, u'cool': 2}  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ  {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg  {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
       "3  uZetl9T0NcROGOyFfughhg  {u'funny': 0, u'useful': 2, u'cool': 1}  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw  {u'funny': 0, u'useful': 0, u'cool': 0}  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print bsnes.head()\n",
    "print checkin.head()\n",
    "print user.head()\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first:  0\n",
      "second:  0\n",
      "first:  0\n",
      "second:  3255\n",
      "first:  0\n",
      "second:  3255\n"
     ]
    }
   ],
   "source": [
    "#All reviews have a business to join to, and we have extra checkins that remain unused \n",
    "mutually_exclusive_elements(bsnes.business_id, review.business_id)\n",
    "mutually_exclusive_elements(checkin.business_id, bsnes.business_id)\n",
    "hm = mutually_exclusive_elements(checkin.business_id, review.business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([      u'business_id',              u'date',         u'review_id',\n",
      "                   u'stars',              u'text',            u'type_x',\n",
      "                 u'user_id',      u'useful_votes',     u'average_stars',\n",
      "               u'user_name', u'user_review_count',            u'type_y',\n",
      "              u'user_votes'],\n",
      "      dtype='object')\n",
      "Index([          u'business_id',                  u'date',\n",
      "                   u'review_id',                 u'stars',\n",
      "                        u'text',                u'type_x',\n",
      "                     u'user_id',          u'useful_votes',\n",
      "               u'average_stars',             u'user_name',\n",
      "           u'user_review_count',                u'type_y',\n",
      "                  u'user_votes',            u'categories',\n",
      "                        u'city',          u'full_address',\n",
      "                    u'latitude',             u'longitude',\n",
      "               u'business_name',         u'neighborhoods',\n",
      "                        u'open', u'business_review_count',\n",
      "              u'business_stars',                 u'state',\n",
      "                        u'type'],\n",
      "      dtype='object')\n",
      "Index([          u'business_id',                  u'date',\n",
      "                   u'review_id',                 u'stars',\n",
      "                        u'text',                u'type_x',\n",
      "                     u'user_id',          u'useful_votes',\n",
      "               u'average_stars',             u'user_name',\n",
      "           u'user_review_count',                u'type_y',\n",
      "                  u'user_votes',            u'categories',\n",
      "                        u'city',          u'full_address',\n",
      "                    u'latitude',             u'longitude',\n",
      "               u'business_name',         u'neighborhoods',\n",
      "                        u'open', u'business_review_count',\n",
      "              u'business_stars',                 u'state',\n",
      "                      u'type_x',          u'checkin_info',\n",
      "                      u'type_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Merge all the data into a single data frame\n",
    "\n",
    "\n",
    "\n",
    "#Apply text transformations on the review text\n",
    "#   Done, now it's a sparse matrix \n",
    "#Do oneHotEncoding or LabelEncoder stuff to categorical variables\n",
    "#   i. OHE takes all potential values for a category and turns them into their own binary feature\n",
    "#   ii. LE makes everything {1,2,...,N} for the # of categories, which is bad if ordinal relationship isn't intended\n",
    "#   iii. OHE is almost always better; only pitfalls are when there are lots of categories and space is an issue, but we\n",
    "#        can solve this by using a PCA on the OHE \n",
    "#Use Normalizer or StandardScaler (sklearn) on the linear variables\n",
    "#   i. I'm not sure why we need to do this.  Look this up \n",
    "#Perform a PCA or TruncatedSVD to reduce dimensionality (probably only necessary due to the text features)\n",
    "#Do feature selection; tons of ways to do this, choose one\n",
    "#Choose a model, train it, test it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
